{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Group matched pid pairs as cluster of matched pids using BFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import pandas as pd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import group_pids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Resolve duplicated entities process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create clusters of matched pids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599810\n",
      "294729\n"
     ]
    }
   ],
   "source": [
    "# Read tables \n",
    "# deterministic_table = pd.read_parquet(\"./linked_data/deterministic_linking_pairs.parquet\", engine = \"pyarrow\").astype(\"string\")\n",
    "# probabilistic_table = pd.read_parquet(\"./linked_data/post_inspection_linked_pairs.parquet\", columns=[\"pid_l\", \"pid_r\"], engine = \"pyarrow\").astype(\"string\")\n",
    "\n",
    "deterministic_table = pd.read_parquet(\"./post_inspection_linked_pairs/post_inspection_dem_link.parquet\", engine = \"pyarrow\").astype(\"string\")\n",
    "probabilistic_table = pd.read_parquet(\"./post_inspection_linked_pairs/post_inspection_prob_link.parquet\", columns=[\"pid_l\", \"pid_r\"], engine = \"pyarrow\").astype(\"string\")\n",
    "\n",
    "# Concatenate pairs from deterministic linking and probabilistic linking (after manual inspection)\n",
    "concat_table = pd.concat([deterministic_table, probabilistic_table])\n",
    "\n",
    "# Convert table to dicitonary\n",
    "pid_map = group_pids.table_to_dict(concat_table)\n",
    "print(len(pid_map))\n",
    "\n",
    "# Compute clusters of matched pids\n",
    "clusters = group_pids.matched_pids(pid_map)\n",
    "print(len(clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select representitive pid of each cluster based on vacdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read personal info table as dictionary\n",
    "personal_info = pd.read_parquet(\"/cluster_data/vrdata/standardized/personal_info.parquet\", columns=[\"pid\", \"vacdate\"], engine = \"pyarrow\")\n",
    "personal_info[\"pid\"] = personal_info[\"pid\"].astype(\"string\")\n",
    "\n",
    "# convert to dictionary for faster vacdate retrieval\n",
    "pid_vacdate = dict()\n",
    "for index, row in personal_info.iterrows():\n",
    "    pid_vacdate[row[\"pid\"]] = row[\"vacdate\"]\n",
    "print(len(pid_vacdate))\n",
    "\n",
    "# clean up unused variables\n",
    "del personal_info\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298730\n"
     ]
    }
   ],
   "source": [
    "# choose pid with the latest vacdate as the representitive pid for each matched cluster\n",
    "pid_cluster = dict() # dictionary of rep pid point to list of pids in the cluster\n",
    "for cluster in clusters:\n",
    "    lastest_vacdate = pid_vacdate[cluster[0]]\n",
    "    rep_pid = cluster[0]\n",
    "    for pid in cluster:\n",
    "        if pid_vacdate[pid]>lastest_vacdate:\n",
    "            lastest_vacdate = pid_vacdate[pid]\n",
    "            rep_pid = pid\n",
    "    pid_cluster[rep_pid] = cluster\n",
    "    \n",
    "print(len(pid_cluster))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create pandas dataframe for pid mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "608091"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Create table with old_pid and new_pid columns\n",
    "# old_pid - non-unique pid in the original dataset\n",
    "# new_pid - updated pid (i.e. representative pid of each cluster)\n",
    "\n",
    "# generate dictionary first as adding rows to dataframe iteratively is extremely inefficient \n",
    "pid_mapping = {\"old_pid\":[], \"unified_pid\":[]}\n",
    "for rep_pid, old_pids in pid_cluster.items():\n",
    "    for pid in old_pids:\n",
    "        pid_mapping[\"old_pid\"].append(pid)\n",
    "        pid_mapping[\"unified_pid\"].append(rep_pid)\n",
    "len(pid_mapping[\"old_pid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(608091, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Convert to pandas dataframe\n",
    "pid_mapping = pd.DataFrame(pid_mapping)\n",
    "pid_mapping.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save result data frame as a parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pid_mapping.to_parquet(\"./unified_pid.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaccine_reg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
