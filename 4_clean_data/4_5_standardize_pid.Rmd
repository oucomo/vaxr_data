---
title: "Update pids based on output generated by 4_4_unify_pids.ipynb"
output:
  html_document:
    df_print: paged
---

## 1. Import libraries
```{r}
library(ArrowDQAToolkit)
library(arrow)
```


## 2. Load dataset that would be updated 
```{r load data}
# load datasets that would be updated
personal_info <- read_parquet(file.path("/./", "cluster_data", "vrdata", "standardized", "personal_info.parquet"), as_data_frame = FALSE)
pathogen_lite <- open_dataset(file.path("/./", "cluster_data", "vrdata", "standardized", "pathogen_lite"))
vacname_lite <- open_dataset(file.path("/./", "cluster_data", "vrdata", "standardized", "vacname_lite"))

unified_pids <- read_parquet("./unified_pid.parquet", as_data_frame = FALSE)
personal_info
```

## 3. Clean data
```{r}
cleaned_data_path <- file.path("/./", "cluster_data", "vrdata", "cleaned")
```

### Clean personal info
```{r update pid in personal_info}
personal_info %>% 
  left_join(
    # join with unified pids
    unified_pids, by = join_by(pid == old_pid)
  ) %>% 
  filter(
    # filter out pids that are mapped to new pid in unified_pids (duplicated entities)
    is.na(unified_pid) | (pid == unified_pid)
  ) %>% 
  select(-unified_pid, -duplicated) %>% 
  compute() %>% 
  write_parquet(file.path(cleaned_data_path, "personal_info.parquet"))
```

### Clean vacname data 
```{r}
vacname_lite <- vacname_lite %>% 
  left_join(
    # join with unified pids
    unified_pids, by = join_by(pid == old_pid)
  ) %>% 
  mutate(
    # update old pid with the unified pid
    pid = ifelse(is.na(unified_pid), pid, unified_pid)
  ) %>% 
  select(-unified_pid) %>%
  compute()
```


```{r run dedup vaccination in personal_info after update pid}
# remove duplicated vaccination records after updating pid
is_dups <- util_compute_duplicates(vacname_lite, vars = c("pid","vacname", "vacdate"))

vacname_lite$is_dups <- is_dups
vacname_lite %>% 
  filter(is_dups==FALSE) %>% 
  select(-is_dups) %>% 
  write_dataset(
    path = file.path(cleaned_data_path, "vacname"),
    format = "parquet",
    partitioning = list("province_reg2")
  )
```

No. record from 153,083,647 reduce to 152,539,312 records (544,335 duplicated records) 


### Clean pathogen data 
```{r update pid in pathogen_lite}
pathogen_lite <- pathogen_lite %>% 
  left_join(
    # join with unified pids
    unified_pids, by = join_by(pid == old_pid)
  ) %>% 
  mutate(
    # update old pids with the unified pids
    pid = ifelse(is.na(unified_pid), pid, unified_pid)
  ) %>% 
  select(-unfied_pid)
  compute()
```

```{r filter out duplicated records} 
is_dups <- util_compute_duplicates(pathogen_lite, vars = c("pid","pathogen", "vacdate"))

# save pathogen dataset after filtering dups
pathogen_lite$is_dups <- as_arrow_array(is_dups)

pathogen_lite %>% 
  filter(!is_dups) %>% 
  select(-is_dups, -unified_pid) %>% 
  write_dataset(
    path = file.path(cleaned_data_path, "pathogen"),
    format = "parquet",
    partitioning = list("pathogen")
  )

cleaned_pathogen_lite <- open_dataset(file.path(cleaned_data_path, "pathogen"))

cleaned_pathogen_lite
```

No. records reduce from 311,482,736 to 309,796,722 records (1,686,014 duplicated records)
