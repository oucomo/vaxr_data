---
title: "Standize names in the dataset, run duplication detection again"
output:
  html_document:
    df_print: paged
---


## 1. Load preprocessed data
```{r}
library(ArrowDQAToolkit)
data_path <- file.path("/.", "cluster_data", "vrdata", "raw", "preprocessed") 
vaccine_path <- file.path("/.", "cluster_data", "vrdata", "vaccine_data")

preprocessed_data <- open_dataset(data_path)

vacname_pathogen <- readRDS(file.path(vaccine_path, "vacname_pathogen.rds"))
vacname_pathogen
vacname_standardized <- readRDS(file.path(vaccine_path, "vacname_standardized.rds"))
vacname_standardized
```

## 2. Create datasets for different use case

- Vaccination dataset that include standardized vacname
- Vaccination dataset that include pathogen instead of vacname
- Personal information dataset that includes personal information for each pid

### 2.1. Create dataset with standardized vacname
```{r standardize vacname}
vacname_standardized <- as_arrow_table(vacname_standardized)
gc()

# join preprocessed_data with vacname_pathogen
# filter rows annotated as SERUM or NOT VACCINE 
standard_vacname_data <- preprocessed_data %>% 
  # standardize spacing before joining
  mutate(vacname = str_replace_all(vacname, "[[:space:]]+", " ")) %>%
  left_join(vacname_standardized, by=join_by(vacname == vacc_name)) %>% # try joining raw_data to standardized vacname
  dplyr::filter(standard_name != "SERUM", standard_name != "NOT VACCINE") %>%
  mutate(vacname = standard_name) %>% 
  select(-standard_name) %>% 
  compute()
```


```{r filter out duplicates}
# --- run duplicate checking
is_dups <- util_compute_duplicates(standard_vacname_data, c("pid","vacname", "vacdate"))
gc()
standard_vacname_data$is_duplicate <- as_arrow_array(is_dups)

# filter out duplicated rows
standard_vacname_data <- standard_vacname_data %>% 
  dplyr::filter(!is_duplicate) %>% 
  select(-is_duplicate) %>% 
  compute()
```
Notable observations:
Dataset have 153,083,647 records after filtering duplicates

```{r save data with standardized vacname}
save_path <- file.path("/.", "cluster_data", "vrdata", "standardized") 
write_dataset(
  dataset = standard_vacname_data,
  path = file.path(save_path, "vacname"),
  format = "parquet",
  partitioning = list("province_reg2")
)

# try loading vacname data
standard_vacname_data <- open_dataset(file.path("/.", "cluster_data", "vrdata", "standardized", "vacname") )
```

#### Generate lite version of standardized vacname dataset
```{r save lite version of standardized vacname dataset}
standard_vacname_data

#--- Generate lite version of standard vacname dataset
standard_vacname_lite <- standard_vacname_data %>% 
  select(pid, vacname, vacdate, vactype, vacplace, vacplace_type, province_reg, district_reg, commune_reg, province_reg2) %>% 
  compute()
standard_vacname_lite

# --- Save lite version of standard vacname dataset
save_path <- file.path("/.", "cluster_data", "vrdata", "standardized") 
write_dataset(
  dataset = standard_vacname_lite,
  path = file.path(save_path, "vacname_lite"),
  format = "parquet",
  partitioning = list("province_reg2")
)
```


### 2.2. Create dataset with pathogen instead of vacname
Create pathogen dataset
```{r pathogen dataset}
# --- reload standardized vacname if crashes due to overloading RAM
data_path <- file.path("/.", "cluster_data", "vrdata", "standardized", "vacname") 
standard_vacname_data <- open_dataset(data_path)

standard_vacname_data %>% 
  select(pid) %>% 
  distinct() %>% 
  compute()

vacname_pathogen <- as_arrow_table(vacname_pathogen)
vacname_standardized <- as_arrow_table(vacname_standardized)
gc()
# --- 

# join vacname_pathogen to standard_vacname to get table of standard vacname to pathogens
standard_vacname_pathogen <- vacname_pathogen %>% 
  full_join(vacname_standardized, by = join_by(vacname == vacc_name)) %>% 
  select(standard_name, pathogen) %>% 
  distinct() %>% 
  compute()

# join standard_vacname with standard_vacname_pathogen
pathogen_data <- standard_vacname_data %>% 
  left_join(standard_vacname_pathogen, by=join_by(vacname == standard_name)) 
```

#### Save pathogen data 
```{r save pathogen dataset}
save_path <- file.path("/.", "cluster_data", "vrdata", "standardized") 
write_dataset(
  dataset = pathogen_data,
  path = file.path(save_path, "pathogen"),
  format = "parquet",
  partitioning = list("pathogen")
)

pathogen_data_lite <- open_dataset(file.path("/.", "cluster_data", "vrdata", "standardized", "pathogen_lite"))
```

#### Load pathogen data and filter duplicates
Filtering algorithmn cannot runs on full dataset (not enough RAM) -> create a lite version of dataset, separating personal info and vaccination shots info

```{r perform duplicate checking}
data_path <- file.path("/.", "cluster_data", "vrdata", "standardized", "pathogen") 
pathogen_data <- open_dataset(data_path)

pathogen_data %>% nrow()
is_dups <- util_compute_duplicates(pathogen_data, c("pid", "vacdate", "pathogen"))
length(which(is_dups))
is_dups <- as_arrow_array(is_dups)

# --- perform duplicate filtering on subset of columns
pathogen_data_lite <- pathogen_data %>% 
  select(pid, vacname, pathogen, vacdate, vactype, vacplace, vacplace_type, province_reg, district_reg, commune_reg) %>% 
  compute()
pathogen_data_lite$is_dups <- is_dups
pathogen_data_lite <- pathogen_data_lite %>% 
  dplyr::filter(!is_dups) %>% 
  select(-is_dups) %>% 
  compute()

pathogen_data_lite
```

Some notable observations
- Pathogen data (without duplicate filtering): 314,081,626 records. (313,705,843 after filtering)
- Unique pids in dataset after filtering NOT VACCINE and SERUM: 14,400,339 pids 
- Number of duplicates in pathogen dataset: 375,783 records

#### Save lite version of pathogen data

```{r Save pathogen dataset after filtering dupicate}
save_path <- file.path("/.", "cluster_data", "vrdata", "standardized") 
write_dataset(
  dataset = pathogen_data_lite,
  path = file.path(save_path, "pathogen_lite"),
  format = "parquet",
  partitioning = list("pathogen")
)

# try loading data 
pathogen_data_lite <- open_dataset(file.path("/.", "cluster_data", "vrdata", "standardized", "pathogen_lite"))
```


### 2.3. Create dataset for personal info only
A lengthy work around to only keep the latest information (based on vacdate) for each pid  

```{r create dataset for personal info only}
# TODO: generate personal info with latest info
# - Get dataset of pid and its latest (max) vacdate
# - Get latest pid info (join with prev dataset on pid, vacdate, select personal info cols then distinct)

# dataset of pid and latest vacdate
pid_lastest_vacdate <- standard_vacname_data %>% 
  select(pid, vacdate) %>% 
  group_by(pid) %>% 
  summarize(
    last_vacdate = max(vacdate)
  ) %>% compute()

# get lastest pid info
personal_info_data <- standard_vacname_data %>% 
  inner_join(pid_lastest_vacdate, by = join_by(pid == pid, vacdate == last_vacdate)) %>% 
  select(pid, name, sex, dob, ethnic, fup, province, district, commune, caregiver, tetanus_status, vacdate, duplicated) %>% 
  distinct() %>% 
  compute() 
```


```{r check personal info dataset}
personal_info_data %>% 
  group_by(pid) %>% 
  count() %>% 
  dplyr::filter(
    n>1
  ) %>% 
  arrange(n) %>% 
  collect()
```

```{r sample error data}
raw_data <- open_dataset("/./cluster_data/vrdata/raw/parquet")

personal_info_data %>% 
  dplyr::filter(
    pid == "701431320210028"
  ) %>% collect()

raw_data %>% filter(
  vacdate == ymd("2021-07-22"),
  pid == "403210920210043"
) %>% collect()
```

Some manual handling for cases where there are different information for a pid, even on the same vacdate
```{r}
personal_info_data <- personal_info_data %>% 
  filter( !(pid == "801152920220053" & (name == caregiver)) ) %>% 
  filter( !(pid == "701150120220090" & (name == caregiver)) ) %>% 
  filter( !(pid == "401511720210007" & (district == "Krông Năng")) ) %>% 
  filter( !(pid == "701130720170496" & !fup ) ) %>% 
  filter( !(pid == "701431320210028" & (province == "Đồng Nai")) ) %>% 
  filter( !(pid == "403210920210043" & (province == "Gia Lai")) ) %>% 
  compute()

nrow(pid_lastest_vacdate) == nrow(personal_info_data)
```


```{r Save personal info dataset}
save_path <- file.path("/.", "cluster_data", "vrdata", "standardized") 
write_parquet(personal_info_data, file.path(save_path, "personal_info.parquet"))

# try reading personal info dataset
personal_data <- read_parquet( file.path("/.", "cluster_data", "vrdata", "standardized", "personal_info.parquet") )
personal_data
```




--- 
### 3. Further analysis after cleaning

#### Load dataset
```{r}
vacname_lite <- open_dataset(file.path("/./", "cluster_data", "vrdata", "standardized", "vacname_lite"))
vacname_lite

pathogen_lite <- open_dataset(file.path("/./", "cluster_data", "vrdata", "standardized", "pathogen_lite"))
pathogen_lite
```

#### Visualize shots per pathogen
```{r}
options(bitmapType='cairo')

pathogen_data_lite %>% 
  count(pathogen) %>% 
  collect() %>% 
  ggplot(aes(
    x = pathogen,
    y = n
  )) +
  geom_bar(stat = "identity", fill = "#308ac2") +
  # scale_y_log10() +
  theme_bw() +
  labs(y = "count") +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=0.8))
```

#### Check jev situation
```{r}
data_path <- file.path("/.", "cluster_data", "vrdata", "standardized") 
pathogen_data_lite <- open_dataset(file.path(data_path, "pathogen_lite"))

# find number of pids with mixed jev shots
pathogen_lite %>% 
  dplyr::filter(pathogen == "jev") %>%
  select(pid, vacname) %>% 
  distinct() %>% 
  group_by(pid) %>% 
  count() %>% 
  dplyr::filter(n>=2) %>% 
  collect()
```
Observations:
- 337,944 pids that takes mixed shots 

```{r sample pids}
pathogen_data_lite %>% 
  dplyr::filter(pid == "225010520150013" & pathogen == "jev") %>% 
  collect()
```




### 4. Contextual data quality after cleaning
#### 4.1. ratio between number of children in dataset vs world pop dataset


#### 4.2. ratio between number of children in dataset vs data from the GSO 
